---
title: "Text as Data - Assignment 3 - Data Exploration"
author: "Jessica Higgins, Nikolina Klatt, Marco Schmildt, Gulce Tuncer"
date: "`r format(Sys.time(), '%B %d, %Y | %H:%M:%S | %Z')`"
output:
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    number_sections: no
    theme: cosmo
    toc: TRUE
---
  
<style>
div.answer {background-color:#f3f0ff; border-radius: 5px; padding: 20px;}
</style>

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      error = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      comment = NA)
```


***

```{r, include = T}
# PACKAGES
library(readr)
library(tidyverse)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
library(purrr)
library(kableExtra)
library(ggplot2)

```

<br>

***

### Data Exploration
```{r}
# load the data 
raw_df <-  read.csv2("data/corpus.csv", # File name or full path of the file
         header = TRUE,        # Whether to read the header or not
         sep = "\t",           # Separator of the values
         quote = "\"",         # Quoting character
         comment.char = "",    # Character of the comments or empty string 
         encoding = "unknown")

raw_df <- raw_df %>% 
  rename(number = X) 

raw_df <- raw_df %>% 
  arrange(year)

glimpse(raw_df)

```


```{r echo=TRUE, message=FALSE, cache=TRUE}
# To split texts by paragraphs 
paragraph_df <- raw_df %>% 
    mutate(text = strsplit(as.character(text), "(\\.\n|\\. \n)")) %>% 
    unnest(text) %>% 
  group_by(country,year) %>% 
  mutate(paragraph_number = 1:n())

glimpse(paragraph_df)
```


```{r}
# How many texts/paragraphs?
paragraph_df %>% 
  nrow() %>% 
  kable(col.names = "Number of texts") %>% 
  kable_styling()
```

```{r}
paragraph_df %>% 
  group_by(year) %>% 
  count
```
```{r}
paragraph_df %>% 
  group_by(year) %>% 
  count %>% 
  ggplot(aes(year, n)) +
  geom_col() +
  labs(x = "Year", y = "number",
title ="Distribution of texts per year")

```



```{r}
paragraph_df %>% 
  head(1) %>% 
  kableExtra::kable() %>% 
  kableExtra::kable_styling()
```

```{r}
speeches <- paragraph_df$text

list <- speeches %>% 
  str_extract_all("(\\b\\w*[Cc]limate [Cc]hange\\w*\\b)") %>% 
  unlist() 

list %>% 
  table() %>% 
  kable(caption = "Frequency of words containing 'climate change'") %>% 
  kable_styling()
```

```{r}
climate_df <- filter(paragraph_df, !grepl("(\\b\\w*[Cc]limate [Cc]hange\\w*\\b)",text))
#climate_df <- filter(raw_df, !grepl("(\\b\\w*[Ww]arming\\w*\\b)",text))

climate_count_df <- climate_df %>% 
  group_by(year) %>% 
  count

climate_count_df %>% 
  ggplot(aes(year, n))+
  geom_col() +
  labs(x = "Year",
       y = "Number of speeches mentioning 'climate change'",
       title ="Frequency of speeches about 'climate change'")

```

```{r}
list_year <-  unique(paragraph_df$year)
freq_df <- as.data.frame(list_year)
freq_df <- freq_df %>% 
  rename(year = list_year) 

pattern = "(\\b\\w*[Cc]limate [Cc]hange\\w*\\b)"

get_length <- function(x){
mentionings <- raw_df %>%
    filter(year == x) %>% 
    select(text) %>% 
    str_extract_all(pattern) %>% 
    unlist
length <- length(mentionings)
return(length)
}

freq_df_0 <- map(list_year, function(x) { # list is the previously created list 
  length <- get_length(x)  # previously created function to get the length
    #length_list <- list(length)
    return(length)
})

freq_df$n <- freq_df_0
freq_df <- freq_df %>% 
  unnest(n)

# Plot the frequency of mentioning words containing "climate" over the years
freq_df %>% 
  ggplot(aes(year, n)) +
  geom_col() +
  labs(x = "Year",
       y = "Number of times",
       title ="Frequency of mentioning words containing 'climate change'")

```


```{r}
# turn data into a corpus
corpus <- corpus(paragraph_df)

# turn corpus into Document Feature Matrix
dfmat <- corpus %>% 
  tokens(., remove_punct = TRUE,
         remove_symbols = TRUE,
         remove_numbers = TRUE) %>%
  tokens_remove(pattern=stopwords("en")) %>% 
  dfm()

print(dfmat, max_ndoc = 0, max_nfeat = 0)
```

```{r}
features_dfm <- textstat_frequency(dfmat, n = 25)

features_dfm %>%
  kable(n=10) %>% 
  kable_styling()

```

```{r}
topfeatures(dfmat, n = 20, scheme = "docfreq") %>% 
  head(10) %>% 
  kable() %>% 
  kable_styling()

```

```{r}
features_dfm$feature <- with(features_dfm, reorder(feature, frequency))

ggplot(features_dfm, aes(x = feature, y = frequency)) +
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  coord_flip()
```

```{r}
wordcloud_dfm <- dfmat %>%
    dfm_trim(min_termfreq = 5000, verbose = TRUE)

wordcloud_dfm %>% 
    textplot_wordcloud()
```

```{r}
# Kew words in context
toks <- tokens(corpus)
kwic(toks, pattern = phrase("climate change"), valuetype = "regex", window = 3)

```
